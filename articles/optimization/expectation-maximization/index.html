<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="If a probabilistic model contains only observable variables, Maximum likelihood estimation or Bayesian methods can be adopted to derive the model parameters. However it is also possible that a probabilistic model contains unobservable variables, or called latent variables." />

  
  <link rel="alternate" hreflang="en-us" href="https://chunxy.github.io/notes/articles/optimization/expectation-maximization/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/notes/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/notes/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/notes/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/notes/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/notes/css/wowchemy.1c7b42a432b4b7b8b2204450dacc9748.css" />

  



  


  


  




  
  
  

  

  
    <link rel="manifest" href="/notes/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/notes/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/notes/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://chunxy.github.io/notes/articles/optimization/expectation-maximization/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
    <meta property="twitter:site" content="@wowchemy" />
    <meta property="twitter:creator" content="@wowchemy" />
  
  <meta property="og:site_name" content="My Notes" />
  <meta property="og:url" content="https://chunxy.github.io/notes/articles/optimization/expectation-maximization/" />
  <meta property="og:title" content="Expectation Maximization | My Notes" />
  <meta property="og:description" content="If a probabilistic model contains only observable variables, Maximum likelihood estimation or Bayesian methods can be adopted to derive the model parameters. However it is also possible that a probabilistic model contains unobservable variables, or called latent variables." /><meta property="og:image" content="https://chunxy.github.io/notes/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_512x512_fill_lanczos_center_3.png" />
    <meta property="twitter:image" content="https://chunxy.github.io/notes/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="article:published_time" content="2022-01-07T12:58:37&#43;00:00" />
    
    <meta property="article:modified_time" content="2022-01-07T12:58:37&#43;00:00">
  

  



  

  

  

  <title>Expectation Maximization | My Notes</title>
</head>


<body id="top" data-spy="scroll"  data-target="#TableOfContents" class="page-wrapper   no-navbar" data-wc-page-id="4696e5d58b467d494856e2233ac2bd94" >

  
  
  
  
  
  
  
  
  
  <script src="/notes/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    


  </div>

  <div class="page-body">
    
    
    

    




<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
        
          Optimization
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">Search...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    
    <ul class="nav docs-sidenav">
      <li class=""><a href="/notes/">Notes</a></li>
    </ul>


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/"><i class="far fa-file-lines pr-1"></i>Articles</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/information-theory/"><img src="/notes/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Information Theory</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/information-theory/entropy/">Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/conditional-entropy/">Conditional Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/cross-entropy/">Cross Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/mutual-information/">Mutual Information</a></li>



  <li class=""><a href="/notes/articles/information-theory/kl-divergence/">KL-divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/f-divergence/">$f$-divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/differentiation/">$\nabla$Differentiation</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/machine-learning/"><img src="/notes/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Machine Learning</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/machine-learning/machine-learning-bullet-points/">Machine Learning Bullet Points</a></li>



  <li class=""><a href="/notes/articles/machine-learning/linear-discriminant-analysis/">Linear Discriminant Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/logistic-regression/">Logistic Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/support-vector-machine/">Support Vector Machine</a></li>



  <li class=""><a href="/notes/articles/machine-learning/linear-regression/">Linear Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/non-linear-regression/">Non-linear Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/clustering/">Clustering</a></li>



  <li class=""><a href="/notes/articles/machine-learning/dimension-reduction/">Dimension Reduction</a></li>



  <li class=""><a href="/notes/articles/machine-learning/principal-component-analysis/">Principal Component Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/eckart-young-mirsky-theorem/">Eckart-Young-Mirsky Theorem</a></li>



  <li class=""><a href="/notes/articles/machine-learning/independent-component-analysis/">Independent Component Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/ransac/">RANSAC</a></li>



  <li class=""><a href="/notes/articles/machine-learning/fishers-linear-discriminant/">Fisher&#39;s Linear Discriminant</a></li>



  <li class=""><a href="/notes/articles/machine-learning/bias-variance-decomposition/">Bias-variance Decomposition</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/"><img src="/notes/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Mathematics</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/calculus/"><img src="/notes/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Calculus</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/calculus/jacobian-matrix/">Jacobian Matrix</a></li>



  <li class=""><a href="/notes/articles/mathematics/calculus/spherical-coordinates/">Spherical Coordinates</a></li>



  <li class=""><a href="/notes/articles/mathematics/calculus/lipschitz-continuity/">Lipschitz Continuity</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/linear-algebra/"><img src="/notes/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Linear Algebra</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/linear-algebra/eigenvectors-and-eigenvalues/">Eigenvectors and Eigenvalues</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/real-symmetric-matrix/">Real Symmetric Matrix</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/singular-value-decomposition/">Singular Value Decomposition</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/matrix-identity/">Matrix Identity</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/laplace-expansion/">Laplace Expansion</a></li>



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/linear-algebra/measures/"><img src="/notes/media/icons/header3.png" alt="header3.png" class="svg-icon svg-baseline pr-1">Measures</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/linear-algebra/measures/spectral-normalization/">Spectral Normalization</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/measures/frobenius-normalization/">Frobenius Normalization</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/measures/chebyshev-distance/">Chebyshev Distance</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/numerical-analysis/"><img src="/notes/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Numerical Analysis</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/numerical-analysis/fourier-transform/">Fourier Transform</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/statistics/"><img src="/notes/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Statistics</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/statistics/unconscious-statistics/">Unconscious Statistics</a></li>



  <li class=""><a href="/notes/articles/mathematics/statistics/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B/">随机变量的收敛</a></li>



  <li class=""><a href="/notes/articles/mathematics/statistics/%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0/">特征函数</a></li>



  <li class=""><a href="/notes/articles/mathematics/statistics/probability-estimation/">Probability Estimation</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/optimization/"><img src="/notes/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Optimization</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/optimization/lagrange-multiplier/">Lagrange Multiplier</a></li>



  <li class=""><a href="/notes/articles/optimization/convex-optimization/">Convex Optimization</a></li>



  <li class=""><a href="/notes/articles/optimization/gradient-descent/">Gradient Descent</a></li>



  <li class=""><a href="/notes/articles/optimization/coordinate-descent/">Coordinate Descent</a></li>



  <li class="active"><a href="/notes/articles/optimization/expectation-maximization/">Expectation Maximization</a></li>



  <li class=""><a href="/notes/articles/optimization/subgradient/">Subgradient</a></li>



  <li class=""><a href="/notes/articles/optimization/least-angle-regression/">Least Angle Regression</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/"><i class="fas fa-book pr-1"></i>Books</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/information-theory-inference-and-learning-algorithms/"><img src="/notes/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Information Theory, Inference and Learning Algorithms</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/source-coding-theory/">Source Coding Theory</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/linear-algebra-and-its-applications/"><img src="/notes/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Linear Algebra and Its Applications</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/least-squares/">Least Squares</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/orthogonality-and-projection/">Orthogonality and Projection</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/coordinate-system-and-change-of-basis/">Coordinate System and Change of Basis</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/schmit-gram-orthogonalization/">Schmit-Gram Orthogonalization</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><img src="/notes/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">概率论与数理统计</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/common-distributions/">Common Distributions</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/gaussian-distribution/">Gaussian Distribution</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/function-of-random-variable/">Function of Random Variable</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%8D%8F%E6%96%B9%E5%B7%AE%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/">协方差与相关系数</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E7%BB%9F%E8%AE%A1%E9%87%8F/">统计量</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/">参数估计</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E4%B8%89%E5%A4%A7%E5%88%86%E5%B8%83%E4%B8%8E%E6%AD%A3%E6%80%81%E6%80%BB%E4%BD%93%E7%9A%84%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/">三大分布与正态总体的抽样分布</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%92%8C%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/">大数定律和中心极限定理</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/"><img src="/notes/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">高等数学</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/limit-computing-tricks/">Limit Computing Tricks</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/papers/"><i class="fas fa-paperclip pr-1"></i>Papers</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/papers/noise-contrastive-estimation/">Noise Contrastive Estimation</a></li>



  <li class=""><a href="/notes/papers/contrastive-predictive-coding/">Contrastive Predictive Coding</a></li>



  <li class=""><a href="/notes/papers/bounding-mutual-information/">Bounding Mutual Information</a></li>

      
        </ul>
      
    

    
      </div>
    

</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents"></nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          
            
  <nav class="d-none d-md-flex" aria-label="breadcrumb">
    <ol class="breadcrumb">
      
  
    
  
    
  
    
  

    <li class="breadcrumb-item">
      <a href="/notes/">
        
          Home
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/articles/">
        
          Articles
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/articles/optimization/">
        
          Optimization
        
      </a>
    </li>
  

      <li class="breadcrumb-item active" aria-current="page">
        Expectation Maximization
      </li>
    </ol>
  </nav>




          
        </div>

        
        

        <div class="docs-article-container">
          <h1>Expectation Maximization</h1>

          <div class="article-style">
            
<p>If a probabilistic model contains only observable variables, Maximum likelihood estimation or Bayesian methods can be adopted to derive the model parameters. However it is also possible that a probabilistic model contains unobservable variables, or called latent variables. Latent variables are those that you cannot observe but you know its existence and effect in the model. In such case, Lagrange Multipliers may be hard to apply because of the existence of the “log of sum” term.</p>
<p>Given samples <span class="math inline">\(X = \{x^{(1)}, x^{(2)}, ..., x^{(m)}\} \in \mathcal{X}\)</span>, and their corresponding latent variables <span class="math inline">\(Z = \{z^{(1)}, z^{(2)}, ..., z^{(m)}\} \in \mathcal{Z}\)</span>, denoting the data as <span class="math inline">\(D = \{(x^{(1)}, z^{(1)}), (x^{(2)}, z^{(2)}), ..., (x^{(m)}, z^{(m)})\}\)</span> try to the find best parameters <span class="math inline">\(\hat \theta\)</span> such that <span class="math display">\[
\hat \theta = arg\max_{\theta}\log(p(X;\theta))
\]</span></p>
<p>The log-likelihood function is <span class="math display">\[
\begin{aligned}
l(\theta) &amp;= \log p(X;\theta) \\
&amp;= \log\sum_{Z \in \mathcal{Z}}p(X, Z;\theta) \\
&amp;= \log\sum_{Z \in \mathcal{Z}}p(Z;\theta)\frac{p(X, Z;\theta)}{p(Z;\theta)} \\
&amp;\ge \sum_{Z \in \mathcal{Z}}p(Z;\theta)\log\frac{p(X, Z;\theta)}{p(Z;\theta)} \text{, by Jensen&#39;s Inequality} \\
&amp;= E_{Z \sim q}[\log\frac{p(X, Z;\theta)}{q(Z)}] \text{, where $q(Z) = p(Z;\theta)$}
\end{aligned}
\]</span></p>
<p>If we maximize the <span class="math inline">\(E_{Z \sim q}[\log\frac{p(X, Z;\theta)}{q(Z)}]\)</span>, the lower bound of <span class="math inline">\(l(\theta)\)</span> can be maximized, which gives us a good guarantee that <span class="math inline">\(l(\theta)\)</span> will increase monotonically. <span class="math inline">\(E_{z \sim q}[\log\frac{p(X, z;\theta)}{q(z)}]\)</span> is a function of <span class="math inline">\((q, \theta)\)</span>, firstly we maximize it w.r.t. <span class="math inline">\(q\)</span>, and then w.r.t. <span class="math inline">\(\theta\)</span>, and then back and forth, making a Coordinate Ascent process.</p>
<p>The first step of Coordinate Ascent, i.e. maximizing over <span class="math inline">\(q\)</span>, happens by having <span class="math inline">\(E_{Z \sim q}[\log\frac{p(X, Z;\theta)}{q(Z)}]\)</span> reach its upper bound when the equality in Jensen’s Inequality holds, where <span class="math inline">\(\log\frac{p(X, Z;\theta)}{q(Z)}\)</span> and thus <span class="math inline">\(\frac{p(X, Z;\theta)}{q(Z)}\)</span> is a constant <span class="math inline">\(c\)</span> for <span class="math inline">\(Z \in \mathcal{Z}\)</span>: <span class="math display">\[
\begin{aligned}
p(X,Z;\theta) &amp;= cq(Z) \\
\sum_Zp(X,Z;\theta) &amp;= c\sum_zq(Z) \\
\sum_Zp(X,Z;\theta) &amp;= c \\
\end{aligned}
\]</span> Then, <span class="math display">\[
q(Z) = \frac{p(X, Z;\theta)}{c} = \frac{p(X, Z;\theta)}{\sum_Zp(X,Z;\theta)} = \frac{p(X, Z;\theta)}{p(X;\theta)} = p(Z|X;\theta)
\]</span> <span class="math inline">\(p(Z|X;\theta)\)</span> is a shorthand for <span class="math inline">\(\frac{p(X, Z;\theta)}{p(X;\theta)}\)</span>: <span class="math display">\[
p(Z|X;\theta) = \frac{p(X, Z;\theta)}{p(X;\theta)} = \frac{\prod_{i=1}^m \sum_{z^{(i)}}p(x^{(i)}, z^{(i)})}{\prod_{i=1}^m p(x^{(i)})} = \prod_{i=1}^m \sum_{z^{(i)}}p(z^{(i)}|x^{(i)})
\]</span></p>
<p><a href="https://www.zhihu.com/question/306016801/answer/624061631">good comparison of latent variables</a></p>



          </div>

          



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/notes/articles/optimization/coordinate-descent/" rel="next">Coordinate Descent</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/notes/articles/optimization/subgradient/" rel="prev">Subgradient</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Jan 7, 2022</p>

          





  

<p class="edit-page">
  <a href="https://github.com/wowchemy/hugo-notes-theme/edit/main/content/Articles/Optimization/Expectation%20Maximization.md">
    <i class="fas fa-pen pr-2"></i>Edit this page
  </a>
</p>



          




          


        </div>

      </article>

      <footer class="site-footer">

  



  

  

  

  
  






  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2022 Chunxy. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>


    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

      

    
    <script src="/notes/js/vendor-bundle.min.53d67dc2cb1ebceb89d5e2aba2f86112.js"></script>

    
    
    
      

      
      

      

    

    
    
    

    
    
    <script src="https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":false}</script>

    
    
    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/notes/en/js/wowchemy.min.b7b574f4c1e92427575caf3142842f4a.js"></script>

    
    
    
    
    
    






</body>
</html>
