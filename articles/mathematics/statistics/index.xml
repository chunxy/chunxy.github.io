<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics | My Notes</title>
    <link>https://chunxy.github.io/notes/articles/mathematics/statistics/</link>
      <atom:link href="https://chunxy.github.io/notes/articles/mathematics/statistics/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistics</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 10 Jul 2022 12:58:49 +0000</lastBuildDate>
    <image>
      <url>https://chunxy.github.io/notes/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_512x512_fill_lanczos_center_3.png</url>
      <title>Statistics</title>
      <link>https://chunxy.github.io/notes/articles/mathematics/statistics/</link>
    </image>
    
    <item>
      <title>随机变量的收敛</title>
      <link>https://chunxy.github.io/notes/articles/mathematics/statistics/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B/</link>
      <pubDate>Wed, 13 Jul 2022 14:41:05 +0000</pubDate>
      <guid>https://chunxy.github.io/notes/articles/mathematics/statistics/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B/</guid>
      <description>

&lt;h2 id=&#34;依概率收敛convergence-in-probability&#34;&gt;依概率收敛（convergence in probability）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;随机变量序列&lt;/strong&gt;即是由随机变量构成。对于一个普通数列&lt;span class=&#34;math inline&#34;&gt;\(\{x_n\}\)&lt;/span&gt;来说，若其收敛于&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;，则当&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;充分大时，&lt;span class=&#34;math inline&#34;&gt;\(x_n\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;的距离可以达到任意小。而随机变量序列&lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2, \dots\)&lt;/span&gt;的极限却不能按照这样定义，因为&lt;span class=&#34;math inline&#34;&gt;\(X_n\)&lt;/span&gt;取值不确定，不可能总和某个数字&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;的距离任意小。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义&lt;/p&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2, \dots,\)&lt;/span&gt;是一个随机变量序列，如果存在一个常数&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;，使得对于任意&lt;span class=&#34;math inline&#34;&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;，都有&lt;span class=&#34;math inline&#34;&gt;\(\lim_{n \to \infty} P(|X_n - c| &amp;lt; \epsilon) = 1\)&lt;/span&gt;，抑或是，对于任意&lt;span class=&#34;math inline&#34;&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;，都有&lt;span class=&#34;math inline&#34;&gt;\(\lim_{n \to \infty} P(|X_n - c| \ge \epsilon) = 0\)&lt;/span&gt;），则称该随机变量序列&lt;strong&gt;依概率收敛&lt;/strong&gt;于&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;，记作&lt;span class=&#34;math inline&#34;&gt;\(X_n \stackrel{P}{\to} c\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;换言之，对于任意&lt;span class=&#34;math inline&#34;&gt;\(\epsilon, \delta &amp;gt; 0\)&lt;/span&gt;，都存在&lt;span class=&#34;math inline&#34;&gt;\(N &amp;gt; 0\)&lt;/span&gt;，使得&lt;span class=&#34;math inline&#34;&gt;\(n &amp;gt; N\)&lt;/span&gt;时，始终有： &lt;span class=&#34;math display&#34;&gt;\[
0 &amp;lt; P(|X_n - c| \ge \epsilon) &amp;lt; \delta
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随机变量是事件的映射，当试验次数足够多时，事件的频率会依概率收敛到该事件的概率。&lt;/p&gt;
&lt;h2 id=&#34;几乎必然收敛almost-sure-convergence&#34;&gt;几乎必然收敛（almost-sure convergence）&lt;/h2&gt;
&lt;p&gt;在某些情况下，若随机变量序列能够和某个数字&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;几乎接近，我们说他几乎必然收敛。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义&lt;/p&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2, \dots,\)&lt;/span&gt;是一个随机变量序列，如果存在一个常数&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;，使得&lt;span class=&#34;math inline&#34;&gt;\(P(\lim_{n \to \infty} X_n = c) = 1\)&lt;/span&gt;，则称该随机变量序列&lt;strong&gt;几乎必然收敛&lt;/strong&gt;于&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;，记作&lt;span class=&#34;math inline&#34;&gt;\(X_n \stackrel{a.s.}{\to} c\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;换言之，对于任意&lt;span class=&#34;math inline&#34;&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;，都存在&lt;span class=&#34;math inline&#34;&gt;\(N &amp;gt; 0\)&lt;/span&gt;，使得&lt;span class=&#34;math inline&#34;&gt;\(n &amp;gt; N\)&lt;/span&gt;时，始终有： &lt;span class=&#34;math display&#34;&gt;\[
P(|X_n - c| &amp;lt; \epsilon) = 1
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;显然，几乎必然收敛是强于依概率收敛的。&lt;/p&gt;
&lt;h2 id=&#34;l_p收敛convergence-in-l_p&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(L_p\)&lt;/span&gt;收敛（convergence in &lt;span class=&#34;math inline&#34;&gt;\(L_p\)&lt;/span&gt;）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义&lt;/p&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2, \dots,\)&lt;/span&gt;是一个随机变量序列，对于某个&lt;span class=&#34;math inline&#34;&gt;\(p \ge 1\)&lt;/span&gt;，如果存在一个常数&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;，使得&lt;span class=&#34;math inline&#34;&gt;\(\E[(\lim_{n \to \infty} X_n - c)^p] \to 0\)&lt;/span&gt;，则称该随机变量序列&lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(L_p\)&lt;/span&gt;收敛&lt;/strong&gt;于&lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;，记作&lt;span class=&#34;math inline&#34;&gt;\(X_n \stackrel{L_p}{\to} c\)&lt;/span&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比较而言，&lt;span class=&#34;math inline&#34;&gt;\(L_P\)&lt;/span&gt;收敛的表达式中多了一层偏差的&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;次方的测度。&lt;/p&gt;
&lt;h3 id=&#34;均方收敛&#34;&gt;均方收敛&lt;/h3&gt;
&lt;p&gt;当&lt;span class=&#34;math inline&#34;&gt;\(p=2\)&lt;/span&gt;时，&lt;span class=&#34;math inline&#34;&gt;\(L_P\)&lt;/span&gt;收敛又称作均方收敛。根据[[大数定律和中心极限定理#Chebyshev不等式|Chebyshev不等式]]： &lt;span class=&#34;math display&#34;&gt;\[
P(|X-\E(X)| \ge \epsilon) \le \frac{\Var(X)}{\epsilon^2} = \frac{\E(X - \E(X))}{\epsilon^2}
\]&lt;/span&gt; 依概率收敛成立时，均方收敛也成立，故均方收敛也比依概率收敛强。但它和几乎必然收敛之间并没有推导关系。&lt;/p&gt;
&lt;h2 id=&#34;依分布收敛convergence-in-distribution&#34;&gt;依分布收敛（convergence in distribution）&lt;/h2&gt;
&lt;p&gt;前面三者描述的是随机变量序列取值的某种特性，而依分布收敛则不同，它描述的是随机变量序列分布函数的特性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义&lt;/p&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1, X_2, \dots,\)&lt;/span&gt;是一个随机变量序列，让&lt;span class=&#34;math inline&#34;&gt;\(F_n\)&lt;/span&gt;表示&lt;span class=&#34;math inline&#34;&gt;\(X_n\)&lt;/span&gt;的分布函数，如果存在一个分布函数&lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;，使得&lt;span class=&#34;math inline&#34;&gt;\(\lim_{n \to \infty} F_n(x) = F(x)\)&lt;/span&gt;，则称该随机变量序列&lt;strong&gt;依分布收敛&lt;/strong&gt;于&lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;，记作&lt;span class=&#34;math inline&#34;&gt;\(X_n \stackrel{d}{\to} F\)&lt;/span&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://zh.m.wikipedia.org/zh/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B&#34;&gt;随机变量的收敛&lt;/a&gt;&lt;/p&gt;


</description>
    </item>
    
    <item>
      <title>Probability Estimation</title>
      <link>https://chunxy.github.io/notes/articles/mathematics/statistics/probability-estimation/</link>
      <pubDate>Sat, 22 Jan 2022 21:36:30 +0000</pubDate>
      <guid>https://chunxy.github.io/notes/articles/mathematics/statistics/probability-estimation/</guid>
      <description>

&lt;h2 id=&#34;probability-estimation&#34;&gt;Probability Estimation&lt;/h2&gt;
&lt;h3 id=&#34;probability-function-estimation&#34;&gt;Probability Function Estimation&lt;/h3&gt;
&lt;h4 id=&#34;monte-carlo-method&#34;&gt;Monte Carlo Method&lt;/h4&gt;
&lt;h3 id=&#34;probability-density-function-estimation&#34;&gt;Probability Density Function Estimation&lt;/h3&gt;
&lt;h4 id=&#34;histogram&#34;&gt;Histogram&lt;/h4&gt;
&lt;h4 id=&#34;parzen-window&#34;&gt;Parzen Window&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/aminor/p/13851150.html&#34;&gt;作图直观理解Parzen窗估计（附Python代码） - aminor - 博客园 (cnblogs.com)&lt;/a&gt; &lt;a href=&#34;https://stats.stackexchange.com/questions/244012/can-you-explain-parzen-window-kernel-density-estimation-in-laymans-terms/244023&#34;&gt;Can you explain Parzen window (kernel) density estimation in layman’s terms? - Cross Validated (stackexchange.com)&lt;/a&gt;&lt;/p&gt;


</description>
    </item>
    
  </channel>
</rss>
