<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="Theorem Any \(m \times n\) matrix \(A\) can be decomposed into \(U\Sigma V^T\), where \[ \begin{gathered} \text{$U$ is $m \times m$, $V$ is $n \times n$} \\ U U^T =" />

  
  <link rel="alternate" hreflang="en-us" href="https://chunxy.github.io/notes/articles/mathematics/linear-algebra/singular-value-decomposition/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.84ebe1e3608d6fadc06cb4d7207008ff.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=G-J44SJXJTFD"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-J44SJXJTFD', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  


  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://chunxy.github.io/notes/articles/mathematics/linear-algebra/singular-value-decomposition/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Chunxy&#39; Website" />
  <meta property="og:url" content="https://chunxy.github.io/notes/articles/mathematics/linear-algebra/singular-value-decomposition/" />
  <meta property="og:title" content="Singular Value Decomposition | Chunxy&#39; Website" />
  <meta property="og:description" content="Theorem Any \(m \times n\) matrix \(A\) can be decomposed into \(U\Sigma V^T\), where \[ \begin{gathered} \text{$U$ is $m \times m$, $V$ is $n \times n$} \\ U U^T =" /><meta property="og:image" content="https://chunxy.github.io/media/sharing.png" />
    <meta property="twitter:image" content="https://chunxy.github.io/media/sharing.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="article:published_time" content="2022-01-07T12:55:32&#43;00:00" />
    
    <meta property="article:modified_time" content="2022-01-07T12:55:32&#43;00:00">
  

  



  

  

  

  <title>Singular Value Decomposition | Chunxy&#39; Website</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="5d1c7485522774dc14e6a6b95481f2e1" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Chunxy&#39; Website</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Chunxy&#39; Website</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/blogs/"><span>Blogs</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/notes/"><span>Notes</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        

        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    




<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
        
          Linear Algebra
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">Search...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      


  
    
    
    
    
      
    
    

    
      <ul class="nav docs-sidenav">
        <li class=""><a href="/notes/">Notes</a></li>
    
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/"><i class="far fa-file-lines pr-1"></i>Articles</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/information-theory/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Information Theory</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/information-theory/entropy/">Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/conditional-entropy/">Conditional Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/cross-entropy/">Cross Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/mutual-information/">Mutual Information</a></li>



  <li class=""><a href="/notes/articles/information-theory/kl-divergence/">KL-divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/f-divergence/">f-divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/jenson-shannon-divergence/">Jenson-Shannon Divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/overview/">Overview</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/machine-learning/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Machine Learning</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/machine-learning/bullet-points/">Bullet Points</a></li>



  <li class=""><a href="/notes/articles/machine-learning/machine-learning-bullet-points/">Machine Learning Bullet Points</a></li>



  <li class=""><a href="/notes/articles/machine-learning/linear-discriminant-analysis/">Linear Discriminant Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/logistic-regression/">Logistic Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/support-vector-machine/">Support Vector Machine</a></li>



  <li class=""><a href="/notes/articles/machine-learning/linear-regression/">Linear Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/non-linear-regression/">Non-linear Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/clustering/">Clustering</a></li>



  <li class=""><a href="/notes/articles/machine-learning/dimensionality-reduction/">Dimension Reduction</a></li>



  <li class=""><a href="/notes/articles/machine-learning/principal-component-analysis/">Principal Component Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/eckart-young-mirsky-theorem/">Eckart-Young-Mirsky Theorem</a></li>



  <li class=""><a href="/notes/articles/machine-learning/independent-component-analysis/">Independent Component Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/ransac/">RANSAC</a></li>



  <li class=""><a href="/notes/articles/machine-learning/fishers-linear-discriminant/">Fisher&#39;s Linear Discriminant</a></li>



  <li class=""><a href="/notes/articles/machine-learning/bias-variance-decomposition/">Bias-variance Decomposition</a></li>



  <li class=""><a href="/notes/articles/machine-learning/mean-average-precision/"></a></li>



  <li class=""><a href="/notes/articles/machine-learning/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"></a></li>



  <li class=""><a href="/notes/articles/machine-learning/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/"></a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Mathematics</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/calculus/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Calculus</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/calculus/jacobian-matrix/">Jacobian Matrix</a></li>



  <li class=""><a href="/notes/articles/mathematics/calculus/spherical-coordinates/">Spherical Coordinates</a></li>



  <li class=""><a href="/notes/articles/mathematics/calculus/lipschitz-continuity/">Lipschitz Continuity</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/linear-algebra/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Linear Algebra</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/linear-algebra/determinant/">Determinant</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/eigenvectors-and-eigenvalues/">Eigenvectors and Eigenvalues</a></li>



  <li class="active"><a href="/notes/articles/mathematics/linear-algebra/singular-value-decomposition/">Singular Value Decomposition</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/real-symmetric-matrix/">Real Symmetric Matrix</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/difference-equation/">Difference Equation</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/matrix-identity/">Matrix Identity</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/quadratic-form/">Quadratic Form</a></li>



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/linear-algebra/metrics/"><img src="/media/icons/header3.png" alt="header3.png" class="svg-icon svg-baseline pr-1">Metrics</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/linear-algebra/metrics/spectral-normalization/">Spectral Normalization</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/metrics/frobenius-normalization/">Frobenius Normalization</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/metrics/chebyshev-distance/">Chebyshev Distance</a></li>

      
        </ul>
      
    

    
      </div>
    



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/positive-semi-definite-matrix/"></a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/numerical-analysis/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Numerical Analysis</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/numerical-analysis/fourier-transform/">Fourier Transform</a></li>



  <li class=""><a href="/notes/articles/mathematics/numerical-analysis/stirlings-approximation/">Stirling&#39;s Approximation</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/probability-and-statistics/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Probability and Statistics</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/law-of-total-variance/">Law of Total Variance</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/gaussian-distribution/">Gaussian Distribution</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/unconscious-statistics/">Unconscious Statistics</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/whitening/">Whitening</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B/">随机变量的收敛</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0/">特征函数</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/optimization/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Optimization</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/optimization/lagrange-multiplier/">Lagrange Multiplier</a></li>



  <li class=""><a href="/notes/articles/optimization/convex-optimization/">Convex Optimization</a></li>



  <li class=""><a href="/notes/articles/optimization/gradient-descent/">Gradient Descent</a></li>



  <li class=""><a href="/notes/articles/optimization/coordinate-descent/">Coordinate Descent</a></li>



  <li class=""><a href="/notes/articles/optimization/expectation-maximization/">Expectation Maximization</a></li>



  <li class=""><a href="/notes/articles/optimization/subgradient/">Subgradient</a></li>



  <li class=""><a href="/notes/articles/optimization/least-angle-regression/">Least Angle Regression</a></li>



  <li class=""><a href="/notes/articles/optimization/convex-conjugate/"></a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/"><i class="fas fa-book pr-1"></i>Books</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/information-theory-inference-and-learning-algorithms/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Information Theory, Inference and Learning Algorithms</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/source-coding-theorem/">Source Coding Theorem</a></li>



  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/source-coding-theory/">Source Coding Theory</a></li>



  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/introduction/"></a></li>



  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/symbol-code/"></a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/linear-algebra-and-its-applications/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Linear Algebra and Its Applications</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/coordinate-system-and-change-of-basis/">Coordinate System and Change of Basis</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/orthogonality-and-projection/">Orthogonality and Projection</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/gram-schmidt-orthogonalization/">Gram-Schmidt Orthogonalization</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/least-squares/">Least Squares</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">概率论与数理统计</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%80%BB%E8%A7%88/">总览</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87/">事件与概率</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83/">常见分布</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%8D%8F%E6%96%B9%E5%B7%AE%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/">协方差与相关系数</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0/">随机变量的函数</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%92%8C%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/">大数定律和中心极限定理</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E4%B8%89%E5%A4%A7%E5%88%86%E5%B8%83%E4%B8%8E%E6%AD%A3%E6%80%81%E6%80%BB%E4%BD%93%E7%9A%84%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/">三大分布与正态总体的抽样分布</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E7%BB%9F%E8%AE%A1%E9%87%8F/">统计量</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/">参数估计</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD/">贝叶斯推断</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/">假设检验</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/papers/"><i class="fas fa-paperclip pr-1"></i>Papers</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/papers/noise-contrastive-estimation/">Noise Contrastive Estimation</a></li>



  <li class=""><a href="/notes/papers/contrastive-predictive-coding/">Contrastive Predictive Coding</a></li>



  <li class=""><a href="/notes/papers/bounding-mutual-information/">Bounding Mutual Information</a></li>



  <li class=""><a href="/notes/papers/flatnce/">FlatNCE</a></li>

      
        </ul>
      
    

    
      </div>
    

      
    

    
      </ul>
    

  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#theorem">Theorem</a></li>
    <li><a href="#proof">Proof</a></li>
    <li><a href="#note">Note</a></li>
    <li><a href="#eckart-young-mirsky-theorem">Eckart-Young-Mirsky
Theorem</a></li>
    <li><a href="#svd-and-diagonalization">SVD and Diagonalization</a></li>
    <li><a href="#external-materials">External materials</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          
            
  <nav class="d-none d-md-flex" aria-label="breadcrumb">
    <ol class="breadcrumb">
      
  
    
  
    
  
    
  
    
  
    
  

    <li class="breadcrumb-item">
      <a href="/">
        
          Home
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/">
        
          Notes
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/articles/">
        
          Articles
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/articles/mathematics/">
        
          Mathematics
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/articles/mathematics/linear-algebra/">
        
          Linear Algebra
        
      </a>
    </li>
  

      <li class="breadcrumb-item active" aria-current="page">
        Singular Value Decomposition
      </li>
    </ol>
  </nav>




          
        </div>

        
        

        <div class="docs-article-container">
          <h1>Singular Value Decomposition</h1>

          <div class="article-style">
            

<h3 id="theorem">Theorem</h3>
<p>Any <span class="math inline">\(m \times n\)</span> matrix <span class="math inline">\(A\)</span> can be decomposed into <span class="math inline">\(U\Sigma V^T\)</span>, where <span class="math display">\[
\begin{gathered}
\text{$U$ is $m \times m$, $V$ is $n \times n$} \\
U U^T = I \\
V V^T = I \\
\Sigma = \diag_{m \times n} (\sigma_1, \sigma_2, ..., \sigma_r) \\
\sigma_1 \ge \sigma_2 \ge ... \ge \sigma_r \ge 0 \\
r = \rank A
\end{gathered}
\]</span></p>
<h3 id="proof">Proof</h3>
<p>This is shown by construction.</p>
<ol type="1">
<li><p>Construction of <span class="math inline">\(V\)</span> and <span class="math inline">\(\Sigma\)</span></p>
<p><span class="math inline">\(A^T A\)</span> is an <span class="math inline">\(n \times n\)</span> real symmetric matrix, so it
can be diagonalized by an orthogonal matrix. Let <span class="math inline">\(V\)</span> be this matrix and <span class="math inline">\(\Lambda\)</span> be the corresponding diagonal
matrix consisting of <span class="math inline">\(A^TA\)</span>’s
eigenvalues: <span class="math display">\[
V^{-1} (A^T A) V = \Lambda
\]</span> Let <span class="math inline">\(\Lambda\)</span> and <span class="math inline">\(V\)</span> be arranged such that corresponding
eigenvalues of <span class="math inline">\(V\)</span> are decreasing.
Because <span class="math inline">\(V\)</span> consists of orthonormal
basis, we have <span class="math inline">\(V^T V = I\)</span>.
Therefore, <span class="math display">\[
V^T (A^T A) V = \Lambda
\]</span> Because <span class="math inline">\(\rank(A) = r\)</span>,
<span class="math inline">\(\rank(A^T A) = r\)</span>. And because <span class="math inline">\(A^T A\)</span> is positive semi-definite, it has
<span class="math inline">\(n\)</span> non-negative real eigenvalues,
<span class="math inline">\(r\)</span> of which are positive. Let <span class="math inline">\(\sigma_i = \sqrt{\lambda_i}, i = 1, 2, ...,
n\)</span> (which are defined as <span class="math inline">\(A\)</span>’s the <strong>singular
values</strong>).</p>
<p><span class="math display">\[
\begin{gather}
\lambda_1, \lambda_2, ..., \lambda_r &gt; 0, \lambda_r, \lambda_{r+1},
..., \lambda_{n} = 0 \\
\sigma_1, \sigma_2, ..., \sigma_r &gt; 0, \sigma_r, \sigma_{r+1}, ...,
\sigma_{n} = 0
\end{gather}
\]</span> Let <span class="math inline">\(V_1 = [v_1, v_2, ..., v_r],
V_2 = [v_{r+1}, v_{r+2}, ..., v_n], V = [V_1, V_2]\)</span>. Also
let</p>
<p><span class="math display">\[
\Sigma_1 =
\begin{bmatrix}
\sigma_1 \\
&amp; \sigma_2 \\
&amp; &amp; \ddots \\
&amp; &amp; &amp; \sigma_r
\end{bmatrix}
\]</span> Complement <span class="math inline">\(\Sigma_1\)</span> with
<span class="math inline">\(0\)</span> to get the <span class="math inline">\(m \times n\)</span> matrix: <span class="math display">\[
\Sigma =
\begin{bmatrix}
\Sigma_1 &amp; 0 \\
0 &amp; 0 \\
\end{bmatrix}
\]</span> Since <span class="math inline">\(\rank(A^T A) = r\)</span>,
<span class="math inline">\(\Nul(A^T A)\)</span> is of dimension <span class="math inline">\(n-r\)</span>. Because <span class="math inline">\(V_2\)</span> comprises of <span class="math inline">\(A^TA\)</span>’s eigenvectors whose eigenvalues are
<span class="math inline">\(0\)</span>, <span class="math inline">\(V_2\)</span> has <span class="math inline">\(n -
r\)</span> independent columns and <span class="math inline">\(A^T A V_2
= 0\)</span>. Therefore, <span class="math inline">\(V_2\)</span> spans
<span class="math inline">\(\Nul(A^TA)\)</span> and thus <span class="math inline">\(\Nul(A)\)</span>. <span class="math display">\[
\begin{gather}
I = VV^T = [V_1, V_2][V_1, V_2]^T = V_1 V_1^T + V_2 V_2^T \\
A = A I = A V_1 V_1^T + A V_2 V_2^T = A V_1 V_1^T
\end{gather}
\]</span></p></li>
<li><p>Construction of <span class="math inline">\(U\)</span></p>
<p>Let <span class="math display">\[
\begin{gather}
u_i \coloneq \frac{1}{\sigma_i} A v_i, i = 1, 2, ..., r \\
U_1 \coloneq [u_1, u_2, ..., u_r]
\end{gather}
\]</span> Thus <span class="math inline">\(AV_1 = U_1\Sigma_1\)</span>.
Also, <span class="math inline">\(U_1\)</span>’s columns are
orthonormal: <span class="math display">\[
\begin{aligned}
u_i^T u_j &amp;= (\frac{1}{\sigma_i} A v_i)^T (\frac{1}{\sigma_j} A v_j)
\\
&amp;= \frac{1}{\sigma_i\sigma_j} v_i^T A^T A v_j \\
&amp;= \frac{1}{\sigma_i\sigma_j} v_i^T \lambda_j v_j \\
&amp;= \frac{\sigma_j}{\sigma_i} v_i^T v_j \\
&amp;=
\begin{cases}
0 &amp; i \ne j \\
1 &amp; i = j
\end{cases}
\end{aligned}
\]</span></p>
<p>Since <span class="math inline">\(u_i\)</span>’s are within <span class="math inline">\(\Col(A)\)</span> and are orthonormal as shown,
plus that <span class="math inline">\(\rank(A) = r\)</span>, <span class="math inline">\(u_i\)</span>’s span the <span class="math inline">\(\Col(A)\)</span>.</p>
<p>Let <span class="math inline">\(\Col(A)^\perp\)</span> be <span class="math inline">\(\Col(A)\)</span>’s complement, we have <span class="math inline">\(\Col(A)^\perp = \Nul(A^T)\)</span>. Let <span class="math inline">\(\{ u_{r+1}, u_{r+2}, \dots, u_{m} \}\)</span> be
an orthonormal basis of <span class="math inline">\(\Nul(A^T)\)</span>
such that they are orthogonal to <span class="math inline">\(U_1\)</span>’s column vectors. We construct <span class="math inline">\(U\)</span> by:</p>
<p><span class="math display">\[
\begin{gather}
U_2 \coloneq [u_{r+1}, u_{r+2}, ..., u_{m}] \\
U \coloneq [U_1, U_2]
\end{gather}
\]</span></p></li>
<li><p>Proof of <span class="math inline">\(U \Sigma V^T = A\)</span>
<span class="math display">\[
\begin{aligned}
U \Sigma V^T &amp;= [U_1, U_2]
\begin{bmatrix}
\Sigma_1 &amp; 0 \\
0 &amp; 0 \\
\end{bmatrix}
\begin{bmatrix}
V_1^T \\
V_2^T \\
\end{bmatrix}
\\
&amp;= [U_1 \Sigma_1, 0]
\begin{bmatrix}
V_1^T \\
V_2^T \\
\end{bmatrix}
\\
&amp;= U_1 \Sigma_1 V_1^T \\
&amp;= A V_1 V_1^T \\
&amp;= A
\end{aligned}
\]</span></p></li>
</ol>
<h3 id="note">Note</h3>
<p>Note that SVD reveals that <span class="math inline">\(A\)</span> is
essentially the addition of <span class="math inline">\(r\)</span>
rank-<span class="math inline">\(1\)</span> matrix: <span class="math display">\[
U \Sigma V^T = \sum_{i=1}^r \sigma_i u_i v_i^T
\]</span> We have shown the construction process of <span class="math inline">\(A\)</span> as <span class="math inline">\(U \Sigma
V^T\)</span> in the above proof, i.e. the existence of such
decomposition, with which we can investigate into <span class="math inline">\(U\)</span>, <span class="math inline">\(\Sigma\)</span> and <span class="math inline">\(V\)</span>. Notice that <span class="math display">\[
\begin{aligned}
A A^T &amp;= U \Sigma V^T V \Sigma U^T \\
A A^T &amp;= U \Sigma^2 U^T \\
A A^T U &amp;= U \Sigma^2 U^T U \\
A A^T U &amp;= U \Sigma^2
\end{aligned}
\]</span> Since <span class="math inline">\(\Sigma\)</span> is a
diagonal matrix, we can conclude that <span class="math inline">\(U\)</span> contains the eigenvectors of <span class="math inline">\(A A^T\)</span>. <span class="math inline">\(\Sigma^2\)</span> contains the eigenvalues of
<span class="math inline">\(A A^T\)</span> as its diagonal entries.
Similarly <span class="math display">\[
\begin{aligned}
A^T A &amp;= V \Sigma U^T U \Sigma V^T \\
A^T A &amp;= V \Sigma^2 V^T \\
A^T A V &amp;= V \Sigma^2 V^T V \\
A^T A V &amp;= V \Sigma^2
\end{aligned}
\]</span> <span class="math inline">\(V\)</span> contains the
eigenvectors of <span class="math inline">\(A^T A\)</span>. <span class="math inline">\(\Sigma^2\)</span> contains the eigenvalues of
<span class="math inline">\(A^T A\)</span> as its diagonal entries.</p>
<p>It is easy to verify that <span class="math inline">\(A A^T\)</span>
and <span class="math inline">\(A^T A\)</span> actually have the same
eigenvalues. And if <span class="math inline">\(v\)</span> is an
eigenvector of <span class="math inline">\(A^T A\)</span>, <span class="math inline">\(A v\)</span> is an eigenvector of <span class="math inline">\(A A^T\)</span> with the same eigenvalue. The
columns of <span class="math inline">\(U\)</span> are called the
<strong>left-singular vectors</strong> of <span class="math inline">\(A\)</span> and the columns of <span class="math inline">\(V\)</span> are called the <strong>right-singular
vectors</strong> of <span class="math inline">\(A\)</span>.</p>
<p>The time complexity of SVD is <span class="math inline">\(O(\min\{
m^2 n, n^2 m \})\)</span>, depending on whether <span class="math inline">\(A A^T\)</span> or <span class="math inline">\(A^T
A\)</span> is used to solve <span class="math inline">\(\Sigma^2\)</span>.</p>
<h2 id="eckart-young-mirsky-theorem">Eckart-Young-Mirsky Theorem</h2>
<p>Given an <span class="math inline">\(m \times n\)</span> matrix <span class="math inline">\(X\)</span> of rank <span class="math inline">\(r
\le \min(m,n)\)</span> and its SVD <span class="math inline">\(X = U
\Sigma V^T\)</span>, where <span class="math inline">\(\Sigma =
\diag(\sigma_1, \sigma_2, ..., \sigma_r)\)</span>, among all the <span class="math inline">\(m \times n\)</span> matrices of rank <span class="math inline">\(k \le r\)</span>, the best approximation to <span class="math inline">\(X\)</span> is <span class="math inline">\(Y^\star
= U \Sigma_k V^T\)</span>, where <span class="math inline">\(\Sigma_k =
\diag(\sigma_1, \sigma_2, ..., \sigma_k)\)</span>, when distance between
<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is defined as <a href="/notes/articles/mathematics/linear-algebra/metrics/frobenius-normalization/">Frobenius norm</a>: <span class="math display">\[
||X - Y||_F = \sqrt{\sum_{ij}(X - Y)_{ij}^2}
\]</span> Notice that in this case, <span class="math display">\[
Y^\star = \sum_{i=1}^k \sigma_k u_k v_k^T
\]</span> Firstly we prove that, if <span class="math inline">\(U\)</span> is orthogonal, then <span class="math inline">\(||U A||_F = ||A U||_F = ||A||_F\)</span>: <span class="math display">\[
\begin{aligned}
||UA||_F^2 &amp;= \tr((U A)^T U A) \\
&amp;= \tr(A^T U U A) \\
&amp;= \tr(A^T A) \\
&amp;= ||A||_F^2
\end{aligned}
\]</span> The same can be derived for <span class="math inline">\(||A
U||_F\)</span>. Then for any <span class="math inline">\(m \times
n\)</span> matrix <span class="math inline">\(Y\)</span> of rank <span class="math inline">\(k \le r\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
&amp;||X - Y||_F^2 = ||U \Sigma V^T - Y||_F^2 \\
&amp;= ||U^T U \Sigma V^T V - U^T Y V||_F^2 \\
&amp;= ||\Sigma - U^T Y V||_F^2 \\
\end{aligned}
\]</span> Let <span class="math inline">\(Z = U^T Y V\)</span>, which is
also of rank <span class="math inline">\(k\)</span>. <span class="math display">\[
\begin{aligned}
&amp;||X - Y||_F^2 = ||\Sigma - Z||_F^2 = \sum_{ij}(\Sigma_{ij} -
Z_{ij})^2 \\
&amp;= \sum_{i=1}^r (\sigma_{i} - Z_{ii})^2 + \sum_{i&gt;r}^{\min(m,n)}
Z_{ii}^2 + \sum_{i \ne j} Z_{ij}^2 \\
\end{aligned}
\]</span> The minimum is achieved if <span class="math display">\[
\begin{gather}
Z_{ii} = \begin{cases}
\sigma_i, &amp; 1 \le i \le r \\
0, &amp; r \le i \le \min(m,n)
\end{cases} \\
Z_{ij} = 0, 1 \le i \le M, 1 \le j \le N, i \ne j
\end{gather}
\]</span> Such <span class="math inline">\(Z\)</span> exists when <span class="math inline">\(Y = U \Sigma_k V^T\)</span>. Q.E.D.</p>
<p>Note that Eckart-Young-Mirsky theorem also holds for <a href="/notes/articles/mathematics/linear-algebra/metrics/spectral-normalization/">spectral norm</a>.</p>
<h2 id="svd-and-diagonalization">SVD and Diagonalization</h2>
<p>It is easy to mix up SVD with <a href="/notes/articles/mathematics/linear-algebra/eigenvectors-and-eigenvalues/#Diagonalization">diagonalization</a>. Notably,
diagonalization factorizes square matrix while SVD factorizes any
matrix. Also, not all square matrices can be diagonalized but all
matrices can be applied with SVD. Finally, SVD can be interpreted as
rotation-scaling-rotation because <span class="math inline">\(U\)</span>
and <span class="math inline">\(V^T\)</span> are orthogonal. But in
diagonalization, <span class="math inline">\(P\)</span> and <span class="math inline">\(P^{-1}\)</span> are not necessarily orthogonal,
unless in the case of real symmetric matrix.</p>
<h2 id="external-materials">External materials</h2>
<p><a href="https://www.cnblogs.com/pinard/p/6251584.html">奇异值分解(SVD)原理与在降维中的应用</a></p>
<p><a href="https://www.zhihu.com/question/22237507">奇异值的物理意义是什么？
- 知乎 (zhihu.com)</a></p>
<p><a href="/uploads/Singular%20Value%20Decomposition.pdf" target="_blank">Singular
Value Decomposition.pdf</a></p>



          </div>

          



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/notes/articles/mathematics/linear-algebra/eigenvectors-and-eigenvalues/" rel="next">Eigenvectors and Eigenvalues</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/notes/articles/mathematics/linear-algebra/real-symmetric-matrix/" rel="prev">Real Symmetric Matrix</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Jan 7, 2022</p>

          



          




          


        </div>

      </article>

      <footer class="site-footer">

  



  

  

  

  
  






  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 Chunxy. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>


    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.6b237408b24ab0ca6e1a289724ba42ac.js"></script>

    
    
    
      

      
      

      

    

    
    
    

    
    
    <script src="https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":false}</script>

    
    
    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.06ae91c9ae146f7126c01e6cceb0a4a6.js"></script>

    
    
    
    
    
    






</body>
</html>
