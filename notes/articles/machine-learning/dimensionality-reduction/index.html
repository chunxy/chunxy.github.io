<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="Unsupervised Dimension Reduction Dimensionality reduction
 reduces computational cost; de-noises by projecting onto lower-dimensional space and back to original space; makes results easier to understand by reducing the collinearity.  Compared to feature selection," />

  
  <link rel="alternate" hreflang="en-us" href="https://chunxy.github.io/notes/articles/machine-learning/dimensionality-reduction/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.84ebe1e3608d6fadc06cb4d7207008ff.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=G-J44SJXJTFD"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-J44SJXJTFD', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  


  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_huc0707d156b6b3b9945e544e63d06d5e5_16450_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://chunxy.github.io/notes/articles/machine-learning/dimensionality-reduction/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="Chunxy&#39; Website" />
  <meta property="og:url" content="https://chunxy.github.io/notes/articles/machine-learning/dimensionality-reduction/" />
  <meta property="og:title" content="Dimension Reduction | Chunxy&#39; Website" />
  <meta property="og:description" content="Unsupervised Dimension Reduction Dimensionality reduction
 reduces computational cost; de-noises by projecting onto lower-dimensional space and back to original space; makes results easier to understand by reducing the collinearity.  Compared to feature selection," /><meta property="og:image" content="https://chunxy.github.io/media/sharing.png" />
    <meta property="twitter:image" content="https://chunxy.github.io/media/sharing.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta property="article:published_time" content="2022-01-07T12:39:56&#43;00:00" />
    
    <meta property="article:modified_time" content="2022-01-07T12:39:56&#43;00:00">
  

  



  

  

  

  <title>Dimension Reduction | Chunxy&#39; Website</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="28bb7a94a07b3b6cdf6c93acf718c2e7" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Chunxy&#39; Website</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Chunxy&#39; Website</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/blogs/"><span>Blogs</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/notes/"><span>Notes</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        

        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    




<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
        
          Machine Learning
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">Search...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      


  
    
    
    
    
      
    
    

    
      <ul class="nav docs-sidenav">
        <li class=""><a href="/notes/">Notes</a></li>
    
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/"><i class="far fa-file-lines pr-1"></i>Articles</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/information-theory/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Information Theory</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/information-theory/entropy/">Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/conditional-entropy/">Conditional Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/cross-entropy/">Cross Entropy</a></li>



  <li class=""><a href="/notes/articles/information-theory/mutual-information/">Mutual Information</a></li>



  <li class=""><a href="/notes/articles/information-theory/kl-divergence/">KL-divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/f-divergence/">f-divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/jenson-shannon-divergence/">Jenson-Shannon Divergence</a></li>



  <li class=""><a href="/notes/articles/information-theory/overview/">Overview</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/machine-learning/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Machine Learning</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/machine-learning/bullet-points/">Bullet Points</a></li>



  <li class=""><a href="/notes/articles/machine-learning/machine-learning-bullet-points/">Machine Learning Bullet Points</a></li>



  <li class=""><a href="/notes/articles/machine-learning/linear-discriminant-analysis/">Linear Discriminant Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/logistic-regression/">Logistic Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/support-vector-machine/">Support Vector Machine</a></li>



  <li class=""><a href="/notes/articles/machine-learning/linear-regression/">Linear Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/non-linear-regression/">Non-linear Regression</a></li>



  <li class=""><a href="/notes/articles/machine-learning/clustering/">Clustering</a></li>



  <li class="active"><a href="/notes/articles/machine-learning/dimensionality-reduction/">Dimension Reduction</a></li>



  <li class=""><a href="/notes/articles/machine-learning/principal-component-analysis/">Principal Component Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/eckart-young-mirsky-theorem/">Eckart-Young-Mirsky Theorem</a></li>



  <li class=""><a href="/notes/articles/machine-learning/independent-component-analysis/">Independent Component Analysis</a></li>



  <li class=""><a href="/notes/articles/machine-learning/ransac/">RANSAC</a></li>



  <li class=""><a href="/notes/articles/machine-learning/fishers-linear-discriminant/">Fisher&#39;s Linear Discriminant</a></li>



  <li class=""><a href="/notes/articles/machine-learning/bias-variance-decomposition/">Bias-variance Decomposition</a></li>



  <li class=""><a href="/notes/articles/machine-learning/mean-average-precision/"></a></li>



  <li class=""><a href="/notes/articles/machine-learning/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"></a></li>



  <li class=""><a href="/notes/articles/machine-learning/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/"></a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Mathematics</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/calculus/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Calculus</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/calculus/jacobian-matrix/">Jacobian Matrix</a></li>



  <li class=""><a href="/notes/articles/mathematics/calculus/spherical-coordinates/">Spherical Coordinates</a></li>



  <li class=""><a href="/notes/articles/mathematics/calculus/lipschitz-continuity/">Lipschitz Continuity</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/linear-algebra/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Linear Algebra</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/linear-algebra/determinant/">Determinant</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/eigenvectors-and-eigenvalues/">Eigenvectors and Eigenvalues</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/singular-value-decomposition/">Singular Value Decomposition</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/real-symmetric-matrix/">Real Symmetric Matrix</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/difference-equation/">Difference Equation</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/matrix-identity/">Matrix Identity</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/quadratic-form/">Quadratic Form</a></li>



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/linear-algebra/metrics/"><img src="/media/icons/header3.png" alt="header3.png" class="svg-icon svg-baseline pr-1">Metrics</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/linear-algebra/metrics/spectral-normalization/">Spectral Normalization</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/metrics/frobenius-normalization/">Frobenius Normalization</a></li>



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/metrics/chebyshev-distance/">Chebyshev Distance</a></li>

      
        </ul>
      
    

    
      </div>
    



  <li class=""><a href="/notes/articles/mathematics/linear-algebra/positive-semi-definite-matrix/"></a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/numerical-analysis/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Numerical Analysis</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/numerical-analysis/fourier-transform/">Fourier Transform</a></li>



  <li class=""><a href="/notes/articles/mathematics/numerical-analysis/stirlings-approximation/">Stirling&#39;s Approximation</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/mathematics/probability-and-statistics/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Probability and Statistics</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/law-of-total-variance/">Law of Total Variance</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/gaussian-distribution/">Gaussian Distribution</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/unconscious-statistics/">Unconscious Statistics</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/whitening/">Whitening</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B/">随机变量的收敛</a></li>



  <li class=""><a href="/notes/articles/mathematics/probability-and-statistics/%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0/">特征函数</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/articles/optimization/"><img src="/media/icons/header2.png" alt="header2.png" class="svg-icon svg-baseline pr-1">Optimization</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/articles/optimization/lagrange-multiplier/">Lagrange Multiplier</a></li>



  <li class=""><a href="/notes/articles/optimization/convex-optimization/">Convex Optimization</a></li>



  <li class=""><a href="/notes/articles/optimization/gradient-descent/">Gradient Descent</a></li>



  <li class=""><a href="/notes/articles/optimization/coordinate-descent/">Coordinate Descent</a></li>



  <li class=""><a href="/notes/articles/optimization/expectation-maximization/">Expectation Maximization</a></li>



  <li class=""><a href="/notes/articles/optimization/subgradient/">Subgradient</a></li>



  <li class=""><a href="/notes/articles/optimization/least-angle-regression/">Least Angle Regression</a></li>



  <li class=""><a href="/notes/articles/optimization/convex-conjugate/"></a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/"><i class="fas fa-book pr-1"></i>Books</a>
    
      
        <ul class="nav docs-sidenav">
      


  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/information-theory-inference-and-learning-algorithms/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Information Theory, Inference and Learning Algorithms</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/source-coding-theorem/">Source Coding Theorem</a></li>



  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/source-coding-theory/">Source Coding Theory</a></li>



  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/introduction/"></a></li>



  <li class=""><a href="/notes/books/information-theory-inference-and-learning-algorithms/symbol-code/"></a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/linear-algebra-and-its-applications/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">Linear Algebra and Its Applications</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/coordinate-system-and-change-of-basis/">Coordinate System and Change of Basis</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/orthogonality-and-projection/">Orthogonality and Projection</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/gram-schmidt-orthogonalization/">Gram-Schmidt Orthogonalization</a></li>



  <li class=""><a href="/notes/books/linear-algebra-and-its-applications/least-squares/">Least Squares</a></li>

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><img src="/media/icons/header1.png" alt="header1.png" class="svg-icon svg-baseline pr-1">概率论与数理统计</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E6%80%BB%E8%A7%88/">总览</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87/">事件与概率</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83/">常见分布</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%8D%8F%E6%96%B9%E5%B7%AE%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/">协方差与相关系数</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%87%BD%E6%95%B0/">随机变量的函数</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%92%8C%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/">大数定律和中心极限定理</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E4%B8%89%E5%A4%A7%E5%88%86%E5%B8%83%E4%B8%8E%E6%AD%A3%E6%80%81%E6%80%BB%E4%BD%93%E7%9A%84%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/">三大分布与正态总体的抽样分布</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E7%BB%9F%E8%AE%A1%E9%87%8F/">统计量</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/">参数估计</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD/">贝叶斯推断</a></li>



  <li class=""><a href="/notes/books/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/">假设检验</a></li>

      
        </ul>
      
    

    
      </div>
    

      
        </ul>
      
    

    
      </div>
    



  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/notes/papers/"><i class="fas fa-paperclip pr-1"></i>Papers</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class=""><a href="/notes/papers/noise-contrastive-estimation/">Noise Contrastive Estimation</a></li>



  <li class=""><a href="/notes/papers/contrastive-predictive-coding/">Contrastive Predictive Coding</a></li>



  <li class=""><a href="/notes/papers/bounding-mutual-information/">Bounding Mutual Information</a></li>



  <li class=""><a href="/notes/papers/flatnce/">FlatNCE</a></li>

      
        </ul>
      
    

    
      </div>
    

      
    

    
      </ul>
    

  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#unsupervised-dimension-reduction">Unsupervised Dimension
Reduction</a>
      <ul>
        <li><a href="#linear-dimensionality-reduction">Linear Dimensionality
Reduction</a></li>
        <li><a href="#non-linear-dimensionality-reduction">Non-linear
Dimensionality Reduction</a></li>
      </ul>
    </li>
    <li><a href="#supervised-dimensionality-reduction">Supervised
Dimensionality Reduction</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          
            
  <nav class="d-none d-md-flex" aria-label="breadcrumb">
    <ol class="breadcrumb">
      
  
    
  
    
  
    
  
    
  

    <li class="breadcrumb-item">
      <a href="/">
        
          Home
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/">
        
          Notes
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/articles/">
        
          Articles
        
      </a>
    </li>
  

    <li class="breadcrumb-item">
      <a href="/notes/articles/machine-learning/">
        
          Machine Learning
        
      </a>
    </li>
  

      <li class="breadcrumb-item active" aria-current="page">
        Dimension Reduction
      </li>
    </ol>
  </nav>




          
        </div>

        
        

        <div class="docs-article-container">
          <h1>Dimension Reduction</h1>

          <div class="article-style">
            

<h2 id="unsupervised-dimension-reduction">Unsupervised Dimension
Reduction</h2>
<p>Dimensionality reduction</p>
<ul>
<li>reduces computational cost;</li>
<li>de-noises by projecting onto lower-dimensional space and back to
original space;</li>
<li>makes results easier to understand by reducing the
collinearity.</li>
</ul>
<p>Compared to feature selection,</p>
<ul>
<li>the goal of feature selection is to remove features that are not
informative with respect to the class label. This obviously reduces the
dimensionality of the feature space;</li>
<li>dimensionality reduction can be used to find a meaningful lower-dim
feature space even when there is information in each feature dimension
so that none can be discarded;</li>
<li>dimensionality reduction is unsupervised while feature selection is
supervised.</li>
</ul>
<p>Compared to data compression,</p>
<ul>
<li>dimensionality reduction can be seen as a simplistic form of data
compression. But they are not equivalent, as the goal of data
compression is to reduce the entropy of the representation, which is not
limited to the dimensionality reduction.</li>
</ul>
<h3 id="linear-dimensionality-reduction">Linear Dimensionality
Reduction</h3>
<p>Linear dimensionality reduction projects data onto lower-dimensional
space by representing the data with a new basis consisting of some major
components. Mathematically, <span class="math display">\[
\begin{gather}
x^{(i)} = \sum_{k=1}^Kz^{(i)}_kb^{(k)}, \text{ where $z^{(i)} \in \R^K$
is the weight, $b^{(k)} \in \R^N$ is the basis vector.} \\
X = BZ, \text{ where $X = [x^{(i)}, \dots, x^{(M)}], B = [b^{(1)},
\dots, b^{(K)}], Z = [z^{(1)}, \dots, z^{(M)}]$}
\end{gather}
\]</span> The objective can be set to minimize the error when recovering
from <span class="math inline">\(B, Z\)</span> to <span class="math inline">\(X\)</span>, i.e. <span class="math display">\[
\min_{B,Z} = ||X - BZ||^2_F = \sum_{ij}(X - BZ)^2_{ij}
\]</span></p>
<h4 id="alternating-least-squares">Alternating Least Squares</h4>
<p>By leveraging the idea of coordinate descent and OLS solution to
linear regression, we can optimize <span class="math inline">\(B\)</span> and <span class="math inline">\(Z\)</span> alternatively, until convergence.</p>
<p>Fix <span class="math inline">\(Z\)</span>, take derivative w.r.t.
<span class="math inline">\(B\)</span> and make it zero to give <span class="math display">\[
\begin{gather}
2(X - BZ)(-Z^T) = 0 \\
BZZ^T = XZ^T \\
B = XZ^T(ZZ^T)^{-1}
\end{gather}
\]</span> Fix <span class="math inline">\(B\)</span>, take derivative
w.r.t. <span class="math inline">\(Z^T\)</span> and make it zero to give
<span class="math display">\[
\begin{gather}
\frac{\partial||X - BZ||^2_F}{\partial Z^T} = \frac{\partial||X^T -
Z^TB^T||^2_F}{\partial Z^T} = 2(X^T - Z^TB^T)(-B) = 0 \\
2(X^T - Z^TB^T)(-B) = 0 \\
Z^TB^TB = X^TB \\
Z^T = X^TB(B^TB)^{-1} \\
Z = (B^TB)^{-1}B^TX
\end{gather}
\]</span> Assume we have run the ALS to convergence and obtain the
global optimal parameters <span class="math display">\[
B^\star, Z^\star = \arg \min_{B,Z} = ||X - BZ||^2_F = \sum_{ij}(X -
BZ)^2_{ij}
\]</span> Let any invertible matrix <span class="math inline">\(R \in
\R^{K \times K}\)</span>. We can construct a pair of <span class="math inline">\(\tilde B, \tilde Z\)</span> such that <span class="math inline">\(\tilde B = B^\star R, \tilde Z =
R^{-1}Z^\star\)</span>. Then, <span class="math display">\[
||X - \tilde B \tilde Z||^2_F = ||X - B^\star RR^{-1} Z^\star||^2_F =
||X - B^\star Z^\star||^2_F
\]</span> Thus the global optima is not unique. We may force
regularization on <span class="math inline">\(B, Z\)</span> and obtain
the unique optima.</p>
<h4 id="principal-component-analysis"><a href="/notes/articles/machine-learning/principal-component-analysis/">Principal Component Analysis</a></h4>
<p>Suppose the SVD for <span class="math inline">\(X\)</span> is <span class="math inline">\(X = U\Sigma V^T\)</span>, where <span class="math display">\[
\begin{gather}
\text{$U$ is $N \times N$, $\Sigma$ is diagonal, $V$ is $M \times M$} \\
UU^T = I \\
VV^T = I \\
\Sigma = diag_{N \times M}(\sigma_1, \sigma_2, ..., \sigma_p) \\
\sigma_1 \ge \sigma_2 \ge ... \ge \sigma_p \ge 0 \\
p = \min\{N,M\}
\end{gather}
\]</span> By only preserving the <span class="math inline">\(K \le
\rank(\Sigma)\)</span> most prominent singular values, <span class="math inline">\(X\)</span> can be approximated as <span class="math inline">\(U_K\Sigma_KV^T_K\)</span>, where <span class="math display">\[
\begin{gather}
\text{$U_K \in \R^{N \times K}$ is first $K$ columns of $U$} \\
\text{$V_K \in \R^{M \times K}$ is first $K$ columns of $V$} \\
\Sigma_K \in \R^{K \times K} = diag(\sigma_1, \sigma_2, ..., \sigma_K)
\\
\end{gather}
\]</span> <a href="/notes/articles/mathematics/linear-algebra/singular-value-decomposition/#Eckart-Young-Mirsky Theorem">Eckart-Young-Mirsky
theorem</a> will tell that <span class="math inline">\(U_K\Sigma_KV^T_K\)</span> is the best
approximation of <span class="math inline">\(X\)</span> among <span class="math inline">\(N \times M\)</span> of rank <span class="math inline">\(K\)</span> in terms of Frobenius norm.</p>
<p>We may obtain the <span class="math inline">\(B^\star,
Z^\star\)</span> by <span class="math display">\[
B^\star = U_K, Z^\star = \Sigma_K V^T_K
\]</span></p>
<p>If the data is centered in advance, <span class="math inline">\(B^\star\)</span> is essentially the principal
component in PCA and <span class="math inline">\(Z^\star\)</span> is the
transformed <span class="math inline">\(X\)</span> in the basis formed
by <span class="math inline">\(B^\star\)</span>.</p>
<h4 id="random-projection">Random Projection</h4>
<p>The above methods all minimize the Frobenius norm during
reconstruction. This objective may become time-consuming when input
dimension becomes large. We may use some randomly-generated vectors as
basis to do the projection. This greatly saves time, at the expense of
losing accuracy. We can measure such projection by checking whether the
structure of the data can be preserved, e.g. the distance between
points.</p>
<p>Johnson-Lindenstrauss Lemma tells that a random function <span class="math inline">\(f(x) = \frac{1}{\sqrt{K}}Ax\)</span>, where <span class="math inline">\(A\)</span> is a <span class="math inline">\(K
\times N\)</span> matrix with i.i.d. entries sampled from a standard
Gaussian, can preserve the distance between any two points within error
<span class="math inline">\(\epsilon\)</span>: <span class="math display">\[
(1 - \epsilon)||x^{(i)} - x^{(j)}||^2_2 \le ||f(x^{(i)}) -
f(x^{j})||^2_2 \le (1 + \epsilon)||x^{(i)} - x^{(j)}||^2_2
\]</span> with the probability at least <span class="math inline">\(\frac{1}{M}\)</span> as long as <span class="math display">\[
K \ge \frac{8\log M}{\epsilon^2}
\]</span> And usually this requirement is quite conservative.</p>
<h3 id="non-linear-dimensionality-reduction">Non-linear Dimensionality
Reduction</h3>
<p>We can introduce the feature mapping to handle the non-linearity
problem in Dimensionality Reduction. Similar to non-linear regression,
we can introduce the kernel trick in this case, yielding the <a href="/notes/articles/machine-learning/principal-component-analysis/#Kernel PCA">Kernel PCA</a>.</p>
<h2 id="supervised-dimensionality-reduction">Supervised Dimensionality
Reduction</h2>
<p>There is no guarantee that the unsupervised Dimension Reduction can
throw insight into the classification problem. It may or may not help.
Otherwise supervised Dimension Reduction such as <a href="/notes/articles/machine-learning/fishers-linear-discriminant/">Fisher’s Linear Discriminant</a> finds
a lower-dimensional space so as to minimize the class overlap.</p>



          </div>

          



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/notes/articles/machine-learning/clustering/" rel="next">Clustering</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/notes/articles/machine-learning/principal-component-analysis/" rel="prev">Principal Component Analysis</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Jan 7, 2022</p>

          



          




          


        </div>

      </article>

      <footer class="site-footer">

  



  

  

  

  
  






  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 Chunxy. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>


    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.6b237408b24ab0ca6e1a289724ba42ac.js"></script>

    
    
    
      

      
      

      

    

    
    
    

    
    
    <script src="https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":false}</script>

    
    
    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.06ae91c9ae146f7126c01e6cceb0a4a6.js"></script>

    
    
    
    
    
    






</body>
</html>
